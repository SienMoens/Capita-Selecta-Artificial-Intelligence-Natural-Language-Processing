{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rdBFyBXsUjkR"
   },
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python 3.12.4' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '/opt/homebrew/bin/python3 -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy.special import softmax\n",
    "import networkx as nx\n",
    "\n",
    "\n",
    "outputs = ['arg0', 'arg1', 'O']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3dY_XqzFMbge"
   },
   "source": [
    "First we define a function so we can print all our matrices and vectors to latex."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2bTI1-eYMfcM"
   },
   "outputs": [],
   "source": [
    "def bmatrix(a):\n",
    "    \"\"\"Returns a LaTeX bmatrix\n",
    "\n",
    "    :a: numpy array\n",
    "    :returns: LaTeX bmatrix as a string\n",
    "    \"\"\"\n",
    "    if len(a.shape) > 2:\n",
    "        raise ValueError('bmatrix can at most display two dimensions')\n",
    "    lines = str(a).replace('[', '').replace(']', '').splitlines()\n",
    "    rv = [r'\\begin{bmatrix}']\n",
    "    rv += ['  ' + ' & '.join(l.split()) + r'\\\\' for l in lines]\n",
    "    rv +=  [r'\\end{bmatrix}']\n",
    "    return '\\n'.join(rv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6fUeY0nFVPjQ"
   },
   "source": [
    "We create the sentence and the vocabulary mappings. The vocabulary contains all unique words and maps to their ids (or the reverse)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 10,
     "status": "ok",
     "timestamp": 1705065310980,
     "user": {
      "displayName": "Nathan Cornille",
      "userId": "07989792410712645375"
     },
     "user_tz": -60
    },
    "id": "W2Qj1vYVU16l"
   },
   "outputs": [],
   "source": [
    "# we define the sentence\n",
    "sent = \"the cat sees the tree with the binoculars\".split()\n",
    "# we create the vocabulary based on the sentence\n",
    "vocab_w2i = {}\n",
    "vocab_i2w = {}\n",
    "for i, w in enumerate(sorted(list(set(sent)))):\n",
    "  vocab_w2i[w] = i\n",
    "  vocab_i2w[i] = w\n",
    "\n",
    "# we transfer the sentence to a list of vocab ids\n",
    "sent_wordids = [vocab_w2i[w] for w in sent]\n",
    "\n",
    "### We create lists for outgoing and incoming connections of each word\n",
    "sent_incoming_nodes = []\n",
    "sent_outgoing_nodes = []\n",
    "for _ in sent:\n",
    "  sent_incoming_nodes.append([])\n",
    "  sent_outgoing_nodes.append([])\n",
    "## we start by adding the neighbours in the sentence\n",
    "for i in range(len(sent)):\n",
    "  # if not the first word\n",
    "  if i != 0:\n",
    "    # add connection with previous word (bidirectional sequence connections)\n",
    "    sent_incoming_nodes[i].append(i-1)\n",
    "    sent_outgoing_nodes[i].append(i-1)\n",
    "  # if not the last word\n",
    "  if i != len(sent)-1:\n",
    "    # add connection with next word (bidirectional sequence connections)\n",
    "    sent_incoming_nodes[i].append(i+1)\n",
    "    sent_outgoing_nodes[i].append(i+1)\n",
    "\n",
    "## now we manually have to add the entire tree as connections\n",
    "# 'the' depends on 'cat'          sent[0], sent[1]\n",
    "sent_incoming_nodes[0].append(1)\n",
    "sent_outgoing_nodes[1].append(0)\n",
    "# 'cat' depends on 'sees'         sent[1], sent[2]\n",
    "sent_incoming_nodes[1].append(2)\n",
    "sent_outgoing_nodes[2].append(1)\n",
    "# 'the' depends on 'tree'         sent[3], sent[4]\n",
    "sent_incoming_nodes[3].append(4)\n",
    "sent_outgoing_nodes[4].append(3)\n",
    "# 'tree' depends on 'sees'        sent[4], sent[2]\n",
    "sent_incoming_nodes[4].append(2)\n",
    "sent_outgoing_nodes[2].append(4)\n",
    "# 'with' depends on 'binoculars'  sent[5], sent[7]\n",
    "sent_incoming_nodes[5].append(7)\n",
    "sent_outgoing_nodes[7].append(5)\n",
    "# 'the' depends on 'binoculars'   sent[6], sent[7]\n",
    "sent_incoming_nodes[6].append(7)\n",
    "sent_outgoing_nodes[7].append(6)\n",
    "# 'binoculars' depends on 'tree'  sent[7], sent[4]\n",
    "sent_incoming_nodes[7].append(4)\n",
    "sent_outgoing_nodes[4].append(7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 319
    },
    "executionInfo": {
     "elapsed": 1259,
     "status": "ok",
     "timestamp": 1668694334710,
     "user": {
      "displayName": "Victor Milewski",
      "userId": "00980338011929053842"
     },
     "user_tz": -60
    },
    "id": "_mXfcy_h1gFn",
    "outputId": "01a55b5e-a73e-443d-934c-047553aeea59"
   },
   "outputs": [],
   "source": [
    "graph = nx.MultiDiGraph()\n",
    "graph.add_nodes_from([(i, {'word': w}) for i, w in enumerate(sent)])\n",
    "for i, l in enumerate(sent_incoming_nodes):\n",
    "    for j in l:\n",
    "        graph.add_edge(i,j)\n",
    "nx.draw(graph, with_labels=True, font_weight='bold')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "icxjyZGHV1sr"
   },
   "source": [
    "let's see what we have:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 258,
     "status": "ok",
     "timestamp": 1705065327530,
     "user": {
      "displayName": "Nathan Cornille",
      "userId": "07989792410712645375"
     },
     "user_tz": -60
    },
    "id": "lnNa3OP1VOBa",
    "outputId": "7df83e83-a070-40fe-a4f3-2be3e86855be"
   },
   "outputs": [],
   "source": [
    "print(\"vocab:\\t\", vocab_i2w)\n",
    "print(sent)\n",
    "print(sent_wordids)\n",
    "print(sent_incoming_nodes)\n",
    "print(sent_outgoing_nodes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TQ9CoBY-mmzq"
   },
   "source": [
    "first we create our word embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 322,
     "status": "ok",
     "timestamp": 1668694342734,
     "user": {
      "displayName": "Victor Milewski",
      "userId": "00980338011929053842"
     },
     "user_tz": -60
    },
    "id": "JoT1zHt_X2dj",
    "outputId": "0a7800a7-5fd4-4494-e404-4132615d62cd"
   },
   "outputs": [],
   "source": [
    "embeddings = np.array([\n",
    "  [-0.5, 0.7],  # binoculars\n",
    "  [1.4, 1.1],   # cat\n",
    "  [0.8, -0.5],    # sees\n",
    "  [-0.3, 0.1],   # the\n",
    "  [1.3, 0.8],  # tree\n",
    "  [0.8, -0.8]   # with\n",
    "])\n",
    "print(embeddings)\n",
    "print(bmatrix(embeddings))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "S-XVGZvXmtPi"
   },
   "source": [
    "and now we create all the weight and biases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 299,
     "status": "ok",
     "timestamp": 1668694409924,
     "user": {
      "displayName": "Victor Milewski",
      "userId": "00980338011929053842"
     },
     "user_tz": -60
    },
    "id": "e5X4wUabX-uS",
    "outputId": "ce389ca1-2cc4-4a4d-d7d4-5a24eb95d857"
   },
   "outputs": [],
   "source": [
    "w_in = np.array([\n",
    "  [-0.5, 0., 0.6],\n",
    "  [-2, 0.5, 1.0],\n",
    "  [2.0, -0.7, -0.8]\n",
    "])\n",
    "w_out = np.array([\n",
    "  [0.1, -1., 1.],\n",
    "  [-0.7, -2., 2.],\n",
    "  [1., 0.3, -0.8]\n",
    "])\n",
    "w_pred = np.array([\n",
    "  [3., -2., 0.2],\n",
    "  [0.1, 2., -3.],\n",
    "  [0.7, -2., 2.]\n",
    "])\n",
    "b_in = np.array([.6, 3., -1.])\n",
    "b_out = np.array([-0.7, 1., 0.2])\n",
    "b_pred = np.array([1,-0.5,-0.5])\n",
    "\n",
    "print(\"w_in:\\n\", w_in, \"\\n\", bmatrix(w_in), \"\\n\")\n",
    "print(\"w_out:\\n\", w_out, \"\\n\", bmatrix(w_out), \"\\n\")\n",
    "print(\"w_pred:\\n\", w_pred, \"\\n\", bmatrix(w_pred), \"\\n\")\n",
    "print(\"b_in:\\n\", b_in, \"\\n\", bmatrix(b_in), \"\\n\")\n",
    "print(\"b_out:\\n\", b_out, \"\\n\", bmatrix(b_out), \"\\n\")\n",
    "print(\"b_pred:\\n\", b_pred,\"\\n\", bmatrix(b_pred), \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "68NJlqUCu6WS"
   },
   "source": [
    "Now let us create our initial hidden states for all the nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 269,
     "status": "ok",
     "timestamp": 1668694411183,
     "user": {
      "displayName": "Victor Milewski",
      "userId": "00980338011929053842"
     },
     "user_tz": -60
    },
    "id": "3Rvz1YRFu6pT",
    "outputId": "904f0fbf-4f44-4216-b88e-baa1dee17124"
   },
   "outputs": [],
   "source": [
    "# lets start by taking all the correct embeddings from the matrix\n",
    "h_0 = np.zeros((len(sent), embeddings.shape[1]))\n",
    "for i, word_id in enumerate(sent_wordids):\n",
    "  h_0[i,:] = embeddings[word_id]\n",
    "print(h_0)\n",
    "\n",
    "# now we concatenate a one hot vector, with a 1 where the predicate is\n",
    "one_hot = np.zeros((len(sent),1))\n",
    "one_hot[2] = 1\n",
    "h_0 = np.concatenate([h_0, one_hot], axis=1)\n",
    "h_0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2cv3E2L8unbW"
   },
   "source": [
    "now we implement the GCN update algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 255,
     "status": "ok",
     "timestamp": 1668694413288,
     "user": {
      "displayName": "Victor Milewski",
      "userId": "00980338011929053842"
     },
     "user_tz": -60
    },
    "id": "a_qGIGvptR69",
    "outputId": "74be3ddb-0f53-46e2-8cb9-8463aa3a459b"
   },
   "outputs": [],
   "source": [
    "h_1 = np.zeros_like(h_0)\n",
    "\n",
    "for i,w in enumerate(sent):\n",
    "  print(f\"\\n\\nupdate h({i}) of word \\\"{w}\\\":\\n------------\")\n",
    "  v_in = np.sum([w_in.T @ h_0[j] + b_in for j in sent_incoming_nodes[i]], axis=0)\n",
    "  v_out = np.sum([w_out.T @ h_0[j] + b_out for j in sent_outgoing_nodes[i]], axis=0)\n",
    "  tmp = h_0[i] + v_in + v_out\n",
    "  h_1[i] = tmp\n",
    "  h_1[i][h_1[i] < 0] = 0\n",
    "  \n",
    "  print(\"v_in:\\n\", (v_in))\n",
    "  print(\"v_out:\\n\", (v_out))\n",
    "  print(\"h_1[i]:\\n\", (tmp))\n",
    "  print(\"RELU h_1[i]:\\n\", (h_1[i]))\n",
    "\n",
    "  print(\"v_in:\\n\", bmatrix(v_in))\n",
    "  print(\"v_out:\\n\", bmatrix(v_out))\n",
    "  print(\"h_1[i]:\\n\", bmatrix(tmp))\n",
    "  print(\"RELU h_1[i]:\\n\", bmatrix(h_1[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5kfvefNiuq6a"
   },
   "source": [
    "So we have the following h at timestep 1:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 53
    },
    "executionInfo": {
     "elapsed": 277,
     "status": "ok",
     "timestamp": 1668694416085,
     "user": {
      "displayName": "Victor Milewski",
      "userId": "00980338011929053842"
     },
     "user_tz": -60
    },
    "id": "2O9EJQOHx7Xx",
    "outputId": "9d774997-7c90-4e19-d2e3-51c5115fcf24"
   },
   "outputs": [],
   "source": [
    "bmatrix(h_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Fbk7u8df0C01"
   },
   "source": [
    "now we make our prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1668694418326,
     "user": {
      "displayName": "Victor Milewski",
      "userId": "00980338011929053842"
     },
     "user_tz": -60
    },
    "id": "hKx_bKoLzxSa",
    "outputId": "ae89fdba-274e-4e47-fa43-5fcce6cde12c"
   },
   "outputs": [],
   "source": [
    "pred = (w_pred.T @ h_1.T).T + b_pred\n",
    "pred_dist = softmax(pred, axis=-1)\n",
    "\n",
    "print(\"pred\\n\", bmatrix(pred))\n",
    "print(\"pred\\n\", (pred))\n",
    "\n",
    "print(\"pred_dist\\n\", bmatrix(pred_dist))\n",
    "print(\"pred_dist\\n\", np.round(pred_dist, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1668694419306,
     "user": {
      "displayName": "Victor Milewski",
      "userId": "00980338011929053842"
     },
     "user_tz": -60
    },
    "id": "8jF-YweP0Q1R",
    "outputId": "2d0fb937-2c4e-4d71-e285-de9d012c2f3a"
   },
   "outputs": [],
   "source": [
    "print(\"Predicted role labels for predicate 'see'\")\n",
    "for i, w in enumerate(sent):\n",
    "  print(\"{:10} {} - {}\".format(w, np.argmax(pred_dist[i]), outputs[np.argmax(pred_dist[i])]))"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
